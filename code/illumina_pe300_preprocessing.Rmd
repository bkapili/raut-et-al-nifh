---
title: "Preprocessing raw Illumina MiSeq PE300 reads"
author: "Bennett J. Kapili"
date: "11/29/2021"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Step 0: Prerequisite installations and downloads

Create conda environment and install R (v.4.1.1), fastqc (v.0.11.9), cutadapt (v.3.5), prinseq (v.0.20.4), and FIGARO (v.1.1.2).
```{bash install software}
# Load modules
ml contribs
ml poldrack
ml anaconda

# Create conda environment
conda config --add channels conda-forge
conda config --add channels bioconda
conda create --prefix /scratch/users/kapili/rault_et_al_nifh
conda activate /scratch/users/kapili/rault_et_al_nifh

# Install preprocessing software
conda install -c bioconda fastqc=0.11.9
conda install -c bioconda cutadapt=3.5
conda install -c bioconda prinseq=0.20.4
conda install -c bioconda figaro=1.1.2

# Install R
conda install -c conda-forge r-base=4.1.1
```

Download raw Illumina MiSeq (PE300) data from SLIMS server.
```{bash download raw data}
# Change directory
DIRPATH=$(echo "$SCRATCH/rault-et-al-nifh")

# Make data subdirectories
eval cd $DIRPATH
mkdir ./data && cd "$_" && mkdir ./raw && cd "$_"

# Download data from SLIMS
wget -r -nH -nc -A "DL13_YR*" --cut-dirs 5    "http://slimsdata.genomecenter.ucdavis.edu/Data/by0xe2e70/210830_M00384_0012_MS3086631-600V3/Unaligned/Project_ADAS_Dekas13_MCRA_NIFH/"

# Unzip (req'd for prinseq)
gzip -d *.fastq.gz
```


# Step 1: Trim primers

Use fastqc (v.0.11.9) to quickly check the quality scores of two samples.
```{bash check quality scores}
# 16S mock communinty
fastqc ./DL13_YR_0108_EP_S76_L001_R1_001.fastq.gz
fastqc ./DL14_E210_1501_BJK_S15_L001_R2_001.fastq.gz
open DL14_E210_1501_BJK_S15_L001_R1_001_fastqc.html
open DL14_E210_1501_BJK_S15_L001_R2_001_fastqc.html

# 4BI
fastqc DL14_E210_1204_BJK_S60_L001_R1_001.fastq.gz
fastqc DL14_E210_1204_BJK_S60_L001_R2_001.fastq.gz
open DL14_E210_1204_BJK_S60_L001_R1_001_fastqc.html
open DL14_E210_1204_BJK_S60_L001_R2_001_fastqc.html
```

Trim mehtaF/mehtaR primer sequences using cutadapt (v.3.5).
```{bash run cutadapt}
# Create new directory
mkdir ../cutadapt; cd ../cutadapt

# Create file of sample names to loop through
ls ../raw/*.fastq | sed 's/_R1_001.fastq//' | sed 's/_R2_001.fastq//' | sed 's/.*\///' | uniq > sample_names.txt

# Set read length filter
EXPECTED_LEN=273

# Loop through samples running cutadapt and print to log
for f in `cat sample_names.txt`; do
  cutadapt \
    --report=minimal \
    -g GGHAARGGHGGHATHGGNAARTC \
    -G GGCATNGCRAANCCVCCRCANAC \
    --discard-untrimmed \
    --max-n=0 \
    --match-read-wildcards \
    -e 0 \
    -m $EXPECTED_LEN -M $EXPECTED_LEN \
    -o "$f"_R1_001_CUTADAPT.fastq \
    -p "$f"_R2_001_CUTADAPT.fastq \
    ../raw/"$f"_R1_001.fastq ../raw/"$f"_R2_001.fastq > tmp.txt
  
  sed -i '1 s/^/sample\t/' tmp.txt
  sed -i "2 s/^/$f\t/" tmp.txt
  
  cat tmp.txt >> cutadapt_log.txt; done
  
rm tmp.txt
```

Add percent reads written column to cutadapt log.
```{r clean cutadapt log}
# Start R session
R

# Required packages
packages <- c("dplyr", "tidyr")

# Install missing packages
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Load packages
library(dplyr)

# Add percent reads written column
df <- read.table(file = "./cutadapt_log.txt", sep = "\t", header = TRUE) %>%
  filter(row_number() %% 2 != 0) %>%
  mutate(percent_written = round(as.integer(out_reads)/as.integer(in_reads)*100, 1)) %>%
  arrange(-percent_written)

# Overwrite existing log
write.table(df, file = "./cutadapt_log.txt", sep = "\t",quote = FALSE, col.names = TRUE, row.names = FALSE)
```

Check that trimmed read lengths match expected lengths. Also check that forward and reverse reads are same lengths. *NOTE:* FIGARO requires forward reads to be the same length and reverse reads to be the same length, not necessarily that both forward and reverse reads are the same length. Since mehtaF/mehtaR are equal lengths, this is a special case where both reads should be the same length.
```{bash check trimmed read lengths}
# Extract max and min read lengths from all trimmed files
for f in `cat sample_names.txt`; do
  prinseq-lite.pl -fastq "$f"_R1_001_CUTADAPT.fastq -stats_len | grep 'max\|min' >> prinseq_log.txt
  prinseq-lite.pl -fastq "$f"_R2_001_CUTADAPT.fastq -stats_len | grep 'max\|min' >> prinseq_log.txt; done

# Check all read lengths are identical and match expected length
TRIMMED_LEN=$(cat prinseq_log.txt | cut -f3 | uniq)

if [ "$TRIMMED_LEN" == "$EXPECTED_LEN" ]; then
  echo "Success! Length of trimmed reads are identical and equal to specified length. Proceed to FIGARO."; else
  echo "Warning! Length of trimmed reads are not identical and/or not equal to specified length. Inspect cutadapt output before proceeding to FIGARO."; fi
  
# Move log files
mkdir ./log; mv *.txt ./log
```


# Step 2: Determine optimal quality-trimming positions for DADA2

Rename files as FIGARO requires.
```{bash rename files}
cd ../cutadapt

rename _CUTADAPT.fastq .fastq  *.fastq
rename DL13_YR_ DL13-YR- *.fastq
rename _EP \\-EP-CUTADAPT *.fastq
for file in *; do mv "$file" "$(echo "$file" | sed 's/\\//g')"; done
```

Run FIGARO requiring minimum overlap of 20 bp. -m set to 18 as workaround to primers being pre-trimmed and primer lengths cannot be set to 0. See [here](https://githubmemory.com/repo/Zymo-Research/figaro/issues/17).
```{bash run figaro}
# Make new directory
mkdir ../figaro; cd ../figaro

# Run FIGARO
figaro.py \
  -i ../cutadapt \
  -o ./ \
  -a 370 \
  -f 1 \
  -r 1 \
  -m 18
```